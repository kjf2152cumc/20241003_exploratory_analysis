---
title: "Exploratory Analysis"
author: "Kaleb J. Frierson"
date: "2024-10-03"
output: 
  github_document:
    toc: TRUE
---

# Notes

group_by() + summarize()

group_by says here is a category that I want to define and then adds a layer ontop of the dataframe that can act transparently unless you call upon it. It is based on existing variables, changes the behavior of some key functions, and is not exactly invisible but is easy to miss. 

summarize() allows you to compute one-number summaries. It is also based on existing variables and is most useful in conjunction with group_by(). 

Exploratory data analysis requires some caution: you should have an analytic plan before doing exploratory analysis so that you don't bias your findings. Most statistical tests assume you're only concnerned about the current hypothesis or that you've done appropriate adjustments for multiple tests/analyses. 


# Coding

## Library Calling

```{r, message=FALSE, warning=FALSE}
library(tidyverse)

```

## Data Import

```{r, message=FALSE, warning=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728", "USW00022534", "USS0023B17S"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2021-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = case_match(
      id, 
      "USW00094728" ~ "CentralPark_NY", 
      "USW00022534" ~ "Molokai_HI",
      "USS0023B17S" ~ "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10,
    month = lubridate::floor_date(date, unit = "month")) |>
  select(name, id, everything())

```

## Plotting

Lets make some plots: 

```{r}
weather_df |> 
  ggplot(aes(x=prcp)) +
  geom_histogram()

```

```{r}
weather_df |> 
  filter(prcp>1000) 
```

```{r}
weather_df |> 
  filter(tmax > 20, tmax < 30) |> 
  ggplot(aes(x= tmin, y= tmax, color = name, shape = name)) + 
  geom_point()
```

Why are central park and molokai each at one whole number while waterhole is all over the place when it comes to decimals? There might be a reporting difference between parks. If we dig into it, central park and molokai are possible reporting in farenheit, converting to celcius, then rounding to some set threshold. Waterhole is probs reporting straight in celcius. 

## group_by()

```{r}
weather_df |> 
  group_by(name)

```

Counting stuff: 

```{r}
weather_df |> 
  group_by(name) |> 
  summarize(n_obs = n())
```

```{r}
weather_df |> 
  group_by(name) |> 
  summarize(n_obs = n(), n_dist = n_distinct(month))
```

There is a special one-off function that does counting by group that you define, in the below case we use name.  

```{r}
weather_df |> 
  count(name)
```

## 2x2 tables

```{r}
weather_df |> 
  drop_na(tmax) |> 
  filter(name != "Molokai_HI") |> 
  mutate(
    cold = case_when(
      tmax < 5 ~ "cold", 
      tmax >=5 ~ "not_cold"
    )
  ) |> 
  group_by(name, cold) |> 
  summarize(count = n())
```
```{r}
weather_df |> 
  drop_na(tmax) |> 
  filter(name != "Molokai_HI") |> 
  mutate(
    cold = case_when(
      tmax < 5 ~ "cold", 
      tmax >=5 ~ "not_cold"
    )
  ) |> 
  janitor::tabyl(name, cold)
```

## general numeric summaries

Useful summaries: 

```{r}
weather_df |> 
  group_by(name) |> 
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE), 
    median_tmin = median(tmin, na.rm = TRUE), 
    sd_prcp = sd(prcp, na.rm = TRUE) 
  )
```

could also do it by month: 

```{r}
weather_df |> 
  group_by(month) |> 
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE), 
    median_tmin = median(tmin, na.rm = TRUE), 
    sd_prcp = sd(prcp, na.rm = TRUE) 
  )
```
or with name and month, then you can plot on the new dataframe too. 

```{r}
weather_df |> 
  group_by(name, month) |> 
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE), 
    median_tmin = median(tmin, na.rm = TRUE), 
    sd_prcp = sd(prcp, na.rm = TRUE) 
  ) |> 
  ggplot(aes(x= month, y= mean_tmax, color = name)) + 
  geom_point()+
  geom_line()
```
The above shows seasonal variation in each of the three weather stations but its more summarized with the criteria that we set. 

Format for readers: 

```{r}
weather_df |> 
  group_by(name, month) |> 
  summarize(
    mean_tmax = mean(tmax, na.rm = TRUE)
  ) |> 
  pivot_wider(
  names_from = name, 
  values_from = mean_tmax
  ) |> 
  knitr::kable(digits=3,
               col.names = c("Month", "Central Park", "Molokai", "Waterhole")
  )
```

Once you've added the grouping layer on top of your df, there are other things you can do as well!

## grouped mutates

```{r}
weather_df |> 
  group_by(name) |> 
  mutate(mean_tmax = mean(tmax, na.rm = TRUE))
```
This demonstrates that the grouping function when working in the tidyverse stays with your dataframe. If later on you get weird results it might be because you forgot that you grouped. So making a grouping permenant is a bad idea. Better in exploratory analysis than when making an analytic dataset. 

```{r}
weather_df |> 
  group_by(name) |> 
  mutate(
    mean_tmax = mean(tmax, na.rm = TRUE), 
    centered_tmax = tmax - mean_tmax) |> 
  ggplot(aes(x = date, y = centered_tmax, color = name)) + 
  geom_point() 
```
```{r}
weather_df |> 
  mutate(
    temp_rank = min_rank(tmax)
  ) |> 
  filter(temp_rank <10)
```
You can also change the way you rank things, use "desc" in the new variable statement with min_rank: temp_rank = min_ranl(desc(tmax))

```{r}
pulse_data = 
  haven::read_sas("data_import_examples/public_pulse_data.sas7bdat") |>
  janitor::clean_names() |>
  pivot_longer(
    bdi_score_bl:bdi_score_12m,
    names_to = "visit", 
    names_prefix = "bdi_score_",
    values_to = "bdi") |>
  select(id, visit, everything()) |>
  mutate(
    visit = replace(visit, visit == "bl", "00m"),
    visit = factor(visit, levels = str_c(c("00", "01", "06", "12"), "m"))) |>
  arrange(id, visit)

pulse_data |> 
  group_by(visit) |> 
  summarize(
    mean_bdi = mean(bdi, na.rm = TRUE),
    median_bdi = median(bdi, na.rm = TRUE)) |> 
  knitr::kable(digits = 3)
```



```{r}
pup_data = 
  read_csv("data_import_examples/FAS_pups.csv") |>
  janitor::clean_names() |>
  mutate(sex = recode(sex, `1` = "male", `2` = "female")) 

litter_data = 
    read_csv("data_import_examples/FAS_litters.csv") |>
  janitor::clean_names() |>
  separate(group, into = c("dose", "day_of_tx"), sep = 3)

fas_data = left_join(pup_data, litter_data, by = "litter_number") 

fas_data |> 
  group_by(dose, day_of_tx) |> 
  drop_na(dose) |> 
  summarize(mean_pivot = mean(pd_pivot, na.rm = TRUE)) |> 
  pivot_wider(
    names_from = dose, 
    values_from = mean_pivot) |> 
  knitr::kable(digits = 3)
```
# FAS dataset
```{r}
litters_df = 
  read_csv("data_import_examples/FAS_litters.csv", na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  separate(
    group, into = c("dose", "tx_day"), sep=3
  )

pups_df = 
  read_csv("data_import_examples/FAS_pups.csv", na = c("NA", "", ".")) |> 
  janitor::clean_names() 

fas_df = 
  left_join(pups_df, litters_df, by = "litter_number")
```


Compute a table we care about: 

```{r}
fas_df |> 
  drop_na(dose) |> 
  group_by(dose, tx_day) |> 
  summarize(mean_pivot = mean(pd_pivot, na.rm = TRUE)) |> 
  pivot_wider(
    names_from = tx_day, 
    values_from = mean_pivot
  ) |> 
  knitr::kable(digits=2)
```

